
## 平均奖励值（Average Reward）

●含义：
衡量智能体在一个训练周期内（或训练结束时）与环境交互获得的平均奖励，代表其“最终表现”。

● 如何评价：
1. 在每一集（episode）中记录总奖励，然后对多集取平均。
2. 通常会画出奖励随训练轮次变化的曲线（reward vs. episode）。
3. 也可以对最后 N 轮（如最后 100 个 episode）求平均作为最终得分。

## 收敛速度（Convergence Speed）
● 含义：
智能体策略变得稳定并接近最优的“速度”或“轮次”。

● 如何评价：
1. 观察训练过程中平均奖励是否快速上升并趋于平稳。
2. 可以画出 moving average 曲线，找出奖励曲线首次稳定达到某个阈值（如 90% 最优奖励）所需的训练轮次。

## 稳定性（Stability）
● 含义：
在训练后期，智能体是否持续表现良好，奖励是否波动很小。

● 如何评价：
1. 观察最后若干轮（如最后 100 个 episode）奖励的方差/标准差。
2. 如果奖励一直在高水平波动较小，说明策略稳定。不稳定则表现为奖励忽高忽低，或频繁掉分。
